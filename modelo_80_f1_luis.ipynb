{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": ".ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP4txCJtkBTfXSuHw0+IQsu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucabem/CompeticionMineria/blob/main/modelo_80_f1_luis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU8xsCCH_A3L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEFpuOSpcBoh"
      },
      "source": [
        "import numpy as np\r\n",
        "import os\r\n",
        "import PIL\r\n",
        "import PIL.Image\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import pathlib"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh8GCRtdcLYv",
        "outputId": "dcf1196b-ce31-4495-b7dd-a506aab0c181"
      },
      "source": [
        "dataset_url = 'https://github.com/lucabem/CompeticionMineria/blob/main/data/dataset_images.zip?raw=true'\r\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url, \r\n",
        "                                   fname='train_data', \r\n",
        "                                   extract=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/lucabem/CompeticionMineria/blob/main/data/dataset_images.zip?raw=true\n",
            "81059840/81057027 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yhP8xGwe36X",
        "outputId": "e4be6694-673b-4555-951f-c37b0501e698"
      },
      "source": [
        "!rm -rf /root/.keras/datasets/train_data.tar.gz /root/.keras/datasets/train_data\r\n",
        "!ls -l /root/.keras/datasets/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 76\n",
            "drwxr-xr-x 28 root root  4096 Mar  5 17:25 ImagesTrain\n",
            "drwxr-xr-x  2 root root 73728 Mar  5 17:25 Test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNAYg6b94G05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a4c6f63-f738-4bc6-bad2-015c3b6a25f9"
      },
      "source": [
        "train_path = pathlib.Path('/root/.keras/datasets/ImagesTrain')\r\n",
        "image_count = len(list(train_path.glob('*/*.jpg')))\r\n",
        "print(image_count)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SifaMI-ahKno"
      },
      "source": [
        "for direct in train_path.iterdir():\r\n",
        "  if direct.is_dir():\r\n",
        "    direct.rename(train_path / direct.name.split(sep='_100')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FGhnAH-goA-"
      },
      "source": [
        "batch_size = 32\r\n",
        "img_height = 224\r\n",
        "img_width  = 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekqQ_EFBcLDp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d0a9eae-3c97-4823-a392-187f94c42c92"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 6.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z9qUelQn-Vo"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CUaZwHscHLV"
      },
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFXO18bRElwL"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator  \r\n",
        "from keras.applications import densenet  \r\n",
        "from keras.models import Sequential, Model, load_model  \r\n",
        "from keras.layers import Conv2D, MaxPooling2D  \r\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense  \r\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback  \r\n",
        "from keras import regularizers  \r\n",
        "from keras import backend as K  \r\n",
        "import tensorflow as tf\r\n",
        "keras = tf.keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI1zuyeIW7XG"
      },
      "source": [
        "batch_size  = 32\r\n",
        "img_height = 224\r\n",
        "img_width  = 224\r\n",
        "train_path = pathlib.Path('/root/.keras/datasets/ImagesTrain')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47e86f3eT-ZX"
      },
      "source": [
        "import shutil\r\n",
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCYAgO1x7Nya"
      },
      "source": [
        "train_ds_gen = ImageDataGenerator(vertical_flip    = True,\r\n",
        "                                  horizontal_flip  = True,\r\n",
        "                                  validation_split = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0Cka5hc9TE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e3a038-826b-4237-fe7f-1cab38e436eb"
      },
      "source": [
        "train_data_gen = train_ds_gen.flow_from_directory(batch_size=batch_size,\r\n",
        "                                                  directory=train_path,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  target_size=(img_height, img_width),\r\n",
        "                                                  subset='training',\r\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2080 images belonging to 26 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZVgGpkwEWqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b9fb43c-5bf2-4109-f017-b7f4f6cb3ec8"
      },
      "source": [
        "valid_data_gen = train_ds_gen.flow_from_directory(batch_size=batch_size,\r\n",
        "                                                  directory=train_path,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  target_size=(img_height, img_width),\r\n",
        "                                                  subset='validation',\r\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 520 images belonging to 26 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpUN4q-bbnKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ef18b19-1bef-480b-db7a-77ee867e0a0c"
      },
      "source": [
        "test_data_gen = train_ds_gen.flow_from_directory(batch_size=batch_size,\r\n",
        "                                                  directory=train_path,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  target_size=(img_height, img_width),\r\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2600 images belonging to 26 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izZ9gyNwZFAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f213b5ec-b3f2-41ac-a81c-44cc48b70de4"
      },
      "source": [
        "base_model = tf.keras.applications.ResNet50(input_shape = (224, 224, 3), \r\n",
        "                                            classes     = 26,\r\n",
        "                                            include_top  = False)\r\n",
        "\r\n",
        "image_batch, label_batch = next(iter(train_data_gen))\r\n",
        "feature_batch = base_model(image_batch)\r\n",
        "base_model.trainable = False\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\r\n",
        "prediction_layer = keras.layers.Dense(26, activation='softmax')\r\n",
        "\r\n",
        "\r\n",
        "model = tf.keras.Sequential([\r\n",
        "  base_model,\r\n",
        "  global_average_layer,\r\n",
        "  prediction_layer\r\n",
        "])\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwL2ctktiRP7"
      },
      "source": [
        "opt = tf.keras.optimizers.Adagrad()\r\n",
        "\r\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='f1_score', patience=5)\r\n",
        "\r\n",
        "model.compile(loss=\"categorical_crossentropy\",\r\n",
        "              optimizer=opt,\r\n",
        "\t            metrics=[tfa.metrics.F1Score(num_classes=26, average='weighted')],\r\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeOc_JCVbyTl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2aa52891-7f0d-47ef-f7be-4b3a67322155"
      },
      "source": [
        "tf.random.set_seed(2021)\r\n",
        "\r\n",
        "model_history = model.fit(  \r\n",
        "    train_data_gen,\r\n",
        "    epochs=24,\r\n",
        "    validation_data=valid_data_gen,\r\n",
        "    validation_steps= valid_data_gen.n // batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/24\n",
            "65/65 [==============================] - 395s 6s/step - loss: 3.2970 - f1_score: 0.0572 - val_loss: 2.5713 - val_f1_score: 0.2226\n",
            "Epoch 2/24\n",
            "65/65 [==============================] - 392s 6s/step - loss: 2.5174 - f1_score: 0.2752 - val_loss: 2.2062 - val_f1_score: 0.4295\n",
            "Epoch 3/24\n",
            "65/65 [==============================] - 388s 6s/step - loss: 2.1463 - f1_score: 0.4607 - val_loss: 1.9527 - val_f1_score: 0.5470\n",
            "Epoch 4/24\n",
            "65/65 [==============================] - 386s 6s/step - loss: 1.9239 - f1_score: 0.5713 - val_loss: 1.7808 - val_f1_score: 0.6114\n",
            "Epoch 5/24\n",
            "65/65 [==============================] - 388s 6s/step - loss: 1.7365 - f1_score: 0.6464 - val_loss: 1.6610 - val_f1_score: 0.6610\n",
            "Epoch 6/24\n",
            "65/65 [==============================] - 387s 6s/step - loss: 1.6339 - f1_score: 0.6694 - val_loss: 1.5447 - val_f1_score: 0.7086\n",
            "Epoch 7/24\n",
            "65/65 [==============================] - 386s 6s/step - loss: 1.5335 - f1_score: 0.7237 - val_loss: 1.4575 - val_f1_score: 0.7343\n",
            "Epoch 8/24\n",
            "65/65 [==============================] - 387s 6s/step - loss: 1.4488 - f1_score: 0.7338 - val_loss: 1.4059 - val_f1_score: 0.7326\n",
            "Epoch 9/24\n",
            "65/65 [==============================] - 388s 6s/step - loss: 1.3660 - f1_score: 0.7412 - val_loss: 1.3551 - val_f1_score: 0.7296\n",
            "Epoch 10/24\n",
            "65/65 [==============================] - 386s 6s/step - loss: 1.3546 - f1_score: 0.7287 - val_loss: 1.2847 - val_f1_score: 0.7628\n",
            "Epoch 11/24\n",
            "65/65 [==============================] - 387s 6s/step - loss: 1.3113 - f1_score: 0.7559 - val_loss: 1.2459 - val_f1_score: 0.7769\n",
            "Epoch 12/24\n",
            "65/65 [==============================] - 386s 6s/step - loss: 1.2517 - f1_score: 0.7626 - val_loss: 1.2060 - val_f1_score: 0.7724\n",
            "Epoch 13/24\n",
            "65/65 [==============================] - 386s 6s/step - loss: 1.1685 - f1_score: 0.7878 - val_loss: 1.1761 - val_f1_score: 0.7937\n",
            "Epoch 14/24\n",
            "65/65 [==============================] - 389s 6s/step - loss: 1.1447 - f1_score: 0.7839 - val_loss: 1.1448 - val_f1_score: 0.7946\n",
            "Epoch 15/24\n",
            "65/65 [==============================] - 386s 6s/step - loss: 1.1303 - f1_score: 0.7846 - val_loss: 1.1271 - val_f1_score: 0.7854\n",
            "Epoch 16/24\n",
            "65/65 [==============================] - 388s 6s/step - loss: 1.1212 - f1_score: 0.7834 - val_loss: 1.1029 - val_f1_score: 0.7942\n",
            "Epoch 17/24\n",
            "65/65 [==============================] - 389s 6s/step - loss: 1.0801 - f1_score: 0.7928 - val_loss: 1.0669 - val_f1_score: 0.7855\n",
            "Epoch 18/24\n",
            "65/65 [==============================] - 389s 6s/step - loss: 1.0607 - f1_score: 0.7828 - val_loss: 1.0513 - val_f1_score: 0.7843\n",
            "Epoch 19/24\n",
            "65/65 [==============================] - 387s 6s/step - loss: 1.0155 - f1_score: 0.8049 - val_loss: 1.0263 - val_f1_score: 0.7983\n",
            "Epoch 20/24\n",
            "65/65 [==============================] - 387s 6s/step - loss: 1.0150 - f1_score: 0.7998 - val_loss: 1.0038 - val_f1_score: 0.8120\n",
            "Epoch 21/24\n",
            "65/65 [==============================] - 388s 6s/step - loss: 1.0196 - f1_score: 0.7892 - val_loss: 0.9891 - val_f1_score: 0.8037\n",
            "Epoch 22/24\n",
            "65/65 [==============================] - 388s 6s/step - loss: 0.9666 - f1_score: 0.8168 - val_loss: 0.9772 - val_f1_score: 0.7912\n",
            "Epoch 23/24\n",
            "65/65 [==============================] - 387s 6s/step - loss: 0.9258 - f1_score: 0.8227 - val_loss: 0.9703 - val_f1_score: 0.7900\n",
            "Epoch 24/24\n",
            "65/65 [==============================] - 387s 6s/step - loss: 0.9250 - f1_score: 0.8273 - val_loss: 0.9471 - val_f1_score: 0.8009\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Knoifs3PzG0S",
        "outputId": "405f906f-2f32-42bc-87c2-80c96388f876"
      },
      "source": [
        "! ls /root/.keras/datasets/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ImagesTrain  Test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOs-NXH4lBQB"
      },
      "source": [
        "batch_size = 32\r\n",
        "img_height = 224\r\n",
        "img_width  = 224\r\n",
        "test_path  = pathlib.Path('/root/.keras/datasets/Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R6hvF4Pk_Fc"
      },
      "source": [
        "# predicting images\r\n",
        "from keras.preprocessing import image\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from google.colab import files\r\n",
        "\r\n",
        "def make_predictions(model_final,\r\n",
        "                     path_test ='/root/.keras/datasets/Test',\r\n",
        "                     name_file_submission = 'submission.csv'):\r\n",
        "\r\n",
        "  images_test = os.listdir(path_test)\r\n",
        "  samples_to_predict = []\r\n",
        "\r\n",
        "  for img in images_test:\r\n",
        "    path_img = os.path.join(path_test, img)\r\n",
        "    img = image.load_img(path_img,\r\n",
        "                        target_size=(img_width, img_height))\r\n",
        "    x = image.img_to_array(img)\r\n",
        "    samples_to_predict.append(x)\r\n",
        "\r\n",
        "  samples_to_predict  = np.array(samples_to_predict)\r\n",
        "  predictions = model_final.predict(samples_to_predict)\r\n",
        "  classes = np.argmax(predictions, axis = 1)\r\n",
        "\r\n",
        "  data = {'id.jpg': [img for img in images_test], 'label': classes}\r\n",
        "  data = pd.DataFrame(data)\r\n",
        "  data.to_csv(name_file_submission, index = False)\r\n",
        "\r\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        },
        "id": "4yZhcH3FXLL_",
        "outputId": "cd1c8ac2-4558-426f-91b6-16c1dbb0a672"
      },
      "source": [
        "make_predictions(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id.jpg</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Forest_DEB_100.0_(-3.7729241933020035_-77.0582...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Forest_CDB_88.03655505180359_(-13.934666687262...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Close_Shrubland_50_90.78353643417358_(-17.8786...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cereal_Cropland_100.0_(52.468799114853_52.2072...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Forest_CEN_84.61316227912903_(29.5696645443054...</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>Forest_OEB_88.33755254745483_(-12.425497009941...</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>Forest_DDB_99.86563920974731_(41.4619216015933...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>Marine_Water_100.0_(71.54470383618786_179.4201...</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>Forest_OEN_86.29198670387268_(56.8554523102654...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>Forest_ODN_78.65363955497742_(65.2263134538048...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>520 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                id.jpg  label\n",
              "0    Forest_DEB_100.0_(-3.7729241933020035_-77.0582...     11\n",
              "1    Forest_CDB_88.03655505180359_(-13.934666687262...      5\n",
              "2    Close_Shrubland_50_90.78353643417358_(-17.8786...      2\n",
              "3    Cereal_Cropland_100.0_(52.468799114853_52.2072...      0\n",
              "4    Forest_CEN_84.61316227912903_(29.5696645443054...      8\n",
              "..                                                 ...    ...\n",
              "515  Forest_OEB_88.33755254745483_(-12.425497009941...     15\n",
              "516  Forest_DDB_99.86563920974731_(41.4619216015933...      4\n",
              "517  Marine_Water_100.0_(71.54470383618786_179.4201...     19\n",
              "518  Forest_OEN_86.29198670387268_(56.8554523102654...     16\n",
              "519  Forest_ODN_78.65363955497742_(65.2263134538048...     10\n",
              "\n",
              "[520 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "id": "bJ02bRvRa66U",
        "outputId": "367e90b6-773c-43b3-9973-594bf750eb4d"
      },
      "source": [
        "while True:pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-534b7a74019f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}