{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": ".ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNv92bfSCbC4QOB/zlL3092",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucabem/CompeticionMineria/blob/main/funcion_pred.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU8xsCCH_A3L"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bEFpuOSpcBoh"
      },
      "source": [
        "import numpy as np\r\n",
        "import os\r\n",
        "import PIL\r\n",
        "import PIL.Image\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_datasets as tfds\r\n",
        "import pathlib"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh8GCRtdcLYv",
        "outputId": "5bf947b5-b48f-4cbc-82af-87560bc30817"
      },
      "source": [
        "dataset_url = 'https://github.com/lucabem/CompeticionMineria/blob/main/data/dataset_images.zip?raw=true'\r\n",
        "data_dir = tf.keras.utils.get_file(origin=dataset_url, \r\n",
        "                                   fname='train_data', \r\n",
        "                                   extract=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/lucabem/CompeticionMineria/blob/main/data/dataset_images.zip?raw=true\n",
            "81059840/81057027 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yhP8xGwe36X",
        "outputId": "105cc12f-45b2-4a7b-df4d-8c075671f56f"
      },
      "source": [
        "!rm -rf /root/.keras/datasets/train_data.tar.gz /root/.keras/datasets/train_data\r\n",
        "!ls -l /root/.keras/datasets/"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 76\n",
            "drwxr-xr-x 28 root root  4096 Mar  5 09:54 ImagesTrain\n",
            "drwxr-xr-x  2 root root 73728 Mar  5 09:54 Test\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNAYg6b94G05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba039cb7-8a5c-401f-f927-a4e3797d3e07"
      },
      "source": [
        "train_path = pathlib.Path('/root/.keras/datasets/ImagesTrain')\r\n",
        "image_count = len(list(train_path.glob('*/*.jpg')))\r\n",
        "print(image_count)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SifaMI-ahKno"
      },
      "source": [
        "for direct in train_path.iterdir():\r\n",
        "  if direct.is_dir():\r\n",
        "    direct.rename(train_path / direct.name.split(sep='_100')[0])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FGhnAH-goA-"
      },
      "source": [
        "batch_size = 32\r\n",
        "img_height = 224\r\n",
        "img_width  = 224"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekqQ_EFBcLDp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd2d95af-b98c-4fe2-f378-a360b346deb2"
      },
      "source": [
        "!pip install tensorflow-addons"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/e3/56d2fe76f0bb7c88ed9b2a6a557e25e83e252aec08f13de34369cd850a0b/tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703kB)\n",
            "\u001b[K     |████████████████████████████████| 706kB 6.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.12.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z9qUelQn-Vo"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2CUaZwHscHLV"
      },
      "source": [
        "import tensorflow_addons as tfa"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFXO18bRElwL"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator  \r\n",
        "from keras.applications import densenet  \r\n",
        "from keras.models import Sequential, Model, load_model  \r\n",
        "from keras.layers import Conv2D, MaxPooling2D  \r\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense  \r\n",
        "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, Callback  \r\n",
        "from keras import regularizers  \r\n",
        "from keras import backend as K  \r\n",
        "import tensorflow as tf\r\n",
        "keras = tf.keras"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qI1zuyeIW7XG"
      },
      "source": [
        "batch_size  = 32\r\n",
        "img_height = 224\r\n",
        "img_width  = 224\r\n",
        "train_path = pathlib.Path('/root/.keras/datasets/ImagesTrain')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47e86f3eT-ZX"
      },
      "source": [
        "import shutil\r\n",
        "import os"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCYAgO1x7Nya"
      },
      "source": [
        "train_ds_gen = ImageDataGenerator(vertical_flip    = True,\r\n",
        "                                  horizontal_flip  = True,\r\n",
        "                                  validation_split = 0.2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c0Cka5hc9TE4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0519a9da-107a-4b6b-e334-9274058c5fcf"
      },
      "source": [
        "train_data_gen = train_ds_gen.flow_from_directory(batch_size=batch_size,\r\n",
        "                                                  directory=train_path,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  target_size=(img_height, img_width),\r\n",
        "                                                  subset='training',\r\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2080 images belonging to 26 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZVgGpkwEWqP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adadcc63-9bd0-4cc3-fd23-28d295aa97c5"
      },
      "source": [
        "valid_data_gen = train_ds_gen.flow_from_directory(batch_size=batch_size,\r\n",
        "                                                  directory=train_path,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  target_size=(img_height, img_width),\r\n",
        "                                                  subset='validation',\r\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 520 images belonging to 26 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpUN4q-bbnKP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089b2540-c7a0-4bf2-a9f0-e46153cd6531"
      },
      "source": [
        "test_data_gen = train_ds_gen.flow_from_directory(batch_size=batch_size,\r\n",
        "                                                  directory=train_path,\r\n",
        "                                                  shuffle=True,\r\n",
        "                                                  target_size=(img_height, img_width),\r\n",
        "                                                  class_mode='categorical')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2600 images belonging to 26 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izZ9gyNwZFAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f509e9f-9d27-4ba0-bc52-d0f725be65de"
      },
      "source": [
        "base_model = tf.keras.applications.ResNet50(input_shape = (224, 224, 3), \r\n",
        "                                            classes     = 26,\r\n",
        "                                            include_top  = False)\r\n",
        "\r\n",
        "image_batch, label_batch = next(iter(train_data_gen))\r\n",
        "feature_batch = base_model(image_batch)\r\n",
        "base_model.trainable = False\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\r\n",
        "prediction_layer = keras.layers.Dense(26, activation='softmax')\r\n",
        "\r\n",
        "\r\n",
        "model = tf.keras.Sequential([\r\n",
        "  base_model,\r\n",
        "  global_average_layer,\r\n",
        "  prediction_layer\r\n",
        "])\r\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwL2ctktiRP7"
      },
      "source": [
        "opt = tf.keras.optimizers.Adagrad()\r\n",
        "\r\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='f1_score', patience=5)\r\n",
        "\r\n",
        "model.compile(loss=\"categorical_crossentropy\",\r\n",
        "              optimizer=opt,\r\n",
        "\t            metrics=[tfa.metrics.F1Score(num_classes=26, average='weighted')],\r\n",
        "              )"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JeOc_JCVbyTl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04c31e09-3340-454e-f81a-cf4e458bf633"
      },
      "source": [
        "tf.random.set_seed(2021)\r\n",
        "\r\n",
        "model_history = model.fit(  \r\n",
        "    train_data_gen,\r\n",
        "    epochs=100,\r\n",
        "    validation_data=valid_data_gen,\r\n",
        "    validation_steps= valid_data_gen.n // batch_size,\r\n",
        "    callbacks=[callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "14/65 [=====>........................] - ETA: 4:05 - loss: 3.7909 - f1_score: 0.0310"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knoifs3PzG0S"
      },
      "source": [
        "! ls /root/.keras/datasets/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOs-NXH4lBQB"
      },
      "source": [
        "batch_size = 32\r\n",
        "img_height = 224\r\n",
        "img_width  = 224\r\n",
        "test_path  = pathlib.Path('/root/.keras/datasets/Test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R6hvF4Pk_Fc"
      },
      "source": [
        "# predicting images\r\n",
        "from keras.preprocessing import image\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "\r\n",
        "def make_predictions(model_final,\r\n",
        "                     path_test ='/root/.keras/datasets/Test',\r\n",
        "                     name_file_submission = 'submission.csv'):\r\n",
        "\r\n",
        "  images_test = os.listdir(path_test)\r\n",
        "  samples_to_predict = []\r\n",
        "\r\n",
        "  for img in images_test:\r\n",
        "    path_img = os.path.join(path_test, img)\r\n",
        "    img = image.load_img(path_img,\r\n",
        "                        target_size=(img_width, img_height))\r\n",
        "    x = image.img_to_array(img)\r\n",
        "    samples_to_predict.append(x)\r\n",
        "\r\n",
        "  samples_to_predict  = np.array(samples_to_predict)\r\n",
        "  predictions = model_final.predict(samples_to_predict)\r\n",
        "  classes = np.argmax(predictions, axis = 1)\r\n",
        "\r\n",
        "  data = {'id.jpg': [img for img in images_test], 'label': classes}\r\n",
        "  data = pd.DataFrame(data)\r\n",
        "  data.to_csv(name_file_submission, index = False)\r\n",
        "\r\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yZhcH3FXLL_"
      },
      "source": [
        "make_predictions(model)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}